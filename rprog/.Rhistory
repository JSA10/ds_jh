library(swirl)
install.packages("swirl")
getwd()
load("~/DataScience/DataScienceDojo/bootcamp/Datasets/.RData")
DSDojoWD
DSDojoDataSetWD
load("~/DataScience/DataScienceDojo/bootcamp/Datasets/DSD_Day2_R_Exploration.RData")
getwd()
DSDojoWDS
library(swirl)
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent.galton)
plot(jitter(child,4) ~ parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col="red")
summary(regrline)
save.image("c:/users/jahye01/Documents/DataScience/R")
save.image("c:/users/jahye01/Documents/DataScience/R/Swirl_LR1.RData")
load("Decision_Tree_Iris_Data.R")
getwd()
DSDojoWDS
load("Decision_Tree_Iris_Data.R")
library(rpart)
data("iris")
dim(iris)
str(iris)
summmary(iris)
summary(iris)
set.seed(???)
set.seed(777)
random.rows.train <- sample(1:nrow(iris), 0.5*nrow(iris), replace=F)
iris.train <- iris[random.rows.train,]
dim(iris.train)
head(iris)
levels(iris$Species)
load("Decision_Tree_Iris_Data.R")
nrow(iris)
1:nrow(iris)
set.seed(777)
random.rows.train <- sample(1:nrow(iris), 0.5*nrow(iris), replace=F)  #return 75 random numbers = 1/2 dataset
iris.train <- iris[random.rows.train,]  #splitting data into a training set
dim(iris.train)
## select the other 1/2 left as the testing data
random.rows.test <- setdiff(1:nrow(iris),random.rows.train)
iris.test <- iris[random.rows.test,]
dim(iris.test)
## fitting decision model on training set
iris.model <- rpart(Species~., data = iris.train)
## VISUALIZE THE MODEL
## visualize the tree structure
plot(iris.model)
title(main = "Decision Tree Model of Iris Data")
text(iris.model, use.n = TRUE)
print(iris.model)
#* indicates to stop splitting at this node
iris.test.predictions <- predict(iris.model, iris.test, type = "class")
#use same predict syntax in multiple models
iris.test.predictions <- predict(iris.model, iris.test, type = "class")
## extract out the observations in testing set
iris.test.observations <- iris.test$Species
## show the confusion matrix
confusion.matrix <- table(iris.test.predictions, iris.test.observations)
confusion.matrix
## calculate the accuracy in testing set
accuracy <- sum(diag(confusion.matrix)) / sum(confusion.matrix)
accuracy
iris.test.predictions
head(iris.test)
iris.test.observations <- iris.test$Species
confusion.matrix <- table(iris.test.predictions, iris.test.observations)
head(iris.test.predictions)
#head of iris.test matches iris.test predictions
head(iris.test.observations)
confusion.matrix
accuracy <- sum(diag(confusion.matrix)) / sum(confusion.matrix)
accuracy
library(party)
intall.packages("party")
install.packages("party")
library(party)
iris.model2 <- ctree(Species~., data = iris.train)
iris.model2
#example of defining parameters
iris.model <- rpart(Species~Sepal.Length, data = iris.train)
iris.model4 <- rpart(Species~Sepal.Length+Petal.Length+Sepal.Width, data = iris.train)
iris.model3 <- rpart(Species~Sepal.Length, data = iris.train)
set.seed(777)
random.rows.train <- sample(1:nrow(iris), 0.5*nrow(iris), replace=F)  #return 75 random numbers = 1/2 dataset
iris.train <- iris[random.rows.train,]  #splitting data into a training set
dim(iris.train)
## select the other 1/2 left as the testing data
random.rows.test <- setdiff(1:nrow(iris),random.rows.train)
iris.test <- iris[random.rows.test,]
dim(iris.test)
## fitting decision model on training set
iris.model <- rpart(Species~., data = iris.train)
iris.model2
ieis.model3
iris.model3
iris.model4
getwd()
DSDojoWDS
#pbinom = at most
#dbinom = exactly
#at least = 1 - pbinom
dbinom(25,size=100,prob=1/6)
pbinom(25,size=100,prob=1/6)
pbinom(6,size=10,prob=1/10)
dbinom(6,size=10,prob=1/10)
1 - pbinom(6,size=10,prob=1/10)
dbinom(10,size=10,prob=1/10)
intall.packages("randomForest")
install.packages("randomForest")
library(randomForest)
#randomForest only used in R as trademarked (if see name 'Forest' in other languages its probably RF)
iris.rf <- randomForest (
Species ~ .,
data=iris,
importance=TRUE,
proximity=TRUE
)
print(iris.rf)
(treesize(randomForest(Species ~ ., data=iris,maxnodes=4, ntree=30)))
#50 setosa correct, 47 versicolor & 3 wrong (virginica), 47 virginica & 3 wrong (versicolor)
#beware this is based on the full dataset. To spl
dim(titanic)
str(titanic)
head(titanic)
summary(titanic)
titanic.data <- titanic.data[, -c(1, 4, 9, 11, 12)]
titanic2 <- titanic[, -c(1, 4, 9, 11, 12)]
titanic2$Survived <- as.factor(titanic2$Survived)
titanic2$Age[is.na(titanic2$Age)] = median(titanic2$Age, na.rm=TRUE)
random.rows.train <- sample(1:nrow(titanic.data), 0.8*nrow(titanic.data), replace=F)
titanic.data <- titanic2
random.rows.train <- sample(1:nrow(titanic.data), 0.8*nrow(titanic.data), replace=F)
random.rows.train
titanic.train <- titanic.data[random.rows.train,]
dim(titanic.train)
random.rows.test <- setdiff(1:nrow(titanic.data),random.rows.train)
titanic.test <- titanic.data[random.rows.test,]
dim(titanic.test)
set.seed(777)
titanic.model <- randomForest(Survived~., data=titanic.train, importance=TRUE, ntree=500)
titanic.model
dim(Zip.test_data)
dim(Zip.train_data)
library(lattice)
levelplot(matrix(zip.train[5,2:257],nrow=16, byrow=TRUE))
library(lattice)
levelplot(matrix(Zip.train_data[5,2:257],nrow=16, byrow=TRUE))
zip.train <- Zip.train_data
zip.train <- subset(zip.train,zip.train$V1==2 | zip.train$V1==3)
zip.train
summary(zip.model)
zip.train <- Zip.train_data
zip.test <- Zip.test_data
zip.train2 <- subset(zip.train,zip.train$V1==2 | zip.train$V1==3)
zip.test2 <- subset(zip.test,zip.test$V1==2 | zip.test$V1==3)
getwd()
DSDojoWDS
install.packages("glmnet")
install.packages("glmnet")
install.packages("Metrics")
library(glmnet)
library(metrics)
install.packages("glmnet")
install.packages("Metrics")
library(glmnet)
library(Metrics)
titanic.data <- read.csv("../../Datasets/Titanic_train.csv", header=TRUE)
## explore the data set
dim(titanic.data)
str(titanic.data)
summary(titanic.data)
## ignore the PassengerID, Name, Ticket, and Cabin
titanic.data <- titanic.data[, -c(1, 4, 9, 11, 12)]
titanic.data$Survived <- as.factor(titanic.data$Survived)
## there are some NAs in Age, fill it with the median value
titanic.data$Age[is.na(titanic.data$Age)] = median(titanic.data$Age, na.rm=TRUE)
titanic.train
dim(titanic.train)
summary(titanic.train)
titanic.data <- titanic.train
titanic.data <- titanic.data[, -c(1, 4, 9, 11, 12)]
titanic.data$Survived <- as.factor(titanic.data$Survived)
## there are some NAs in Age, fill it with the median value
titanic.data$Age[is.na(titanic.data$Age)] = median(titanic.data$Age, na.rm=TRUE)
random.rows.train <- sample(1:nrow(titanic.data), 0.8*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[random.rows.train,]
dim(titanic.train)
## select the other 20% as the testing data
random.rows.test <- setdiff(1:nrow(titanic.data),random.rows.train)
titanic.test <- titanic.data[random.rows.test,]
dim(titanic.test)
## fitting decision model on training set
set.seed(777)
x <- model.matrix(Survived~., data=titanic.train)[,-1] # glmnet requires matrix as input of glmnet function
titanic.model <- glmnet(x, titanic.train$Survived, family="binomial", lambda=0.001)
titanic.model
library(stats)
library(fpc)
install.packages("fpc")
View(DwellTimeA_data)
view(zip.train)
head(zip.train)
zip.data <- zip.train
set.seed(100)
random.rows <- sample(1:nrow(zip.data),500,replace=F)
zip.data <- zip.data[random.rows,]
zip.train <- as.data.frame(scale(zip.data[,-1]))
head(zip.train)
?kmeans
zip.model <- kmeans(zip.train, 10, iter.max = 100, nstart = 25)
zip.model
zip.kmean.clusters <- lapply(1:10, function(nc)zip.data[zip.model$cluster==nc, 1])
zip.kmean.clusters
plotcluster(zip.train, zip.data$V1, xlab="dc1", ylab="dc2", method="dc")
library(stats)
library(fpc)
install.packages("fpc")
plotcluster(zip.train, zip.data$V1, xlab="dc1", ylab="dc2", method="dc")
?plotcluster
install.packages("plotcluster")
plot(zip.train, zip.data$V1, xlab="dc1", ylab="dc2", method="dc")
save<-
save.image("c:/users/jahye01/Documents/DataScience/DataScienceDojo/Datasets/Day5_Console.RData")
save.image("c:/users/jahye01/Documents/DataScience/DataScienceDojo/bootcamp/Datasets/Day5_Console.RData")
hack <- read.csv("Hacking.csv")
setwd("~/Pitches")
setwd("~/Pitches/Kaspersky")
hack <- read.csv("Hacking.csv")
str(hack)
View(hack)
Dates <- strptime(hack$Date, "%d/%M/%Y") #helps R convert to format it understands
head(Dates)
ggplot(hack, aes(x=Posts, y=Date. group=1)) + geom_line()
ggplot(hack, aes(x=Posts, y=Date, group=1)) + geom_line()
library(ggplot2)
ggplot(hack, aes(x=Posts, y=Date, group=1)) + geom_line()
ggplot(hack, aes(x=Date, y=Posts, group=1)) + geom_line()
ggplot(hack, aes(x=Date, y=Posts, group=7)) + geom_line()
ggplot(hack, aes(x=Date, y=Posts, group=30)) + geom_line()
p_month2 <- 5000 / 15
isobar_pulsar <- p_month2 * 5
t_isobar_pulsar <- isobar_pulsar *12
rm("mydf") #to remove individual datasets or functions from environment
cat("\014")
getwd()
setwd("/Users/jahye01/Documents/Jerome/Money")
getwd()
rep(1:8, each=20)
jerome_sal <- rep(2386, 12)
rm(list = ls())
jerome_sal <- rep(2386, 12)
jerome_sal
2016 <- month.name
2016 <- vector(month.name)
month.name
becca_mon <- 2558 / 2
becca_stat <- 110 * 4.5
becca_stat <- 600
becca_sal <- c(rep(becca_mon, 4), rep(becca_stat, 3))
becca_ben <- 90
becca_sal <- c(rep(becca_mon, 4), rep(becca_stat, 3), rep(becca_ben, 4)
becca_sal <- c(rep(becca_mon, 4), rep(becca_stat, 3), rep(becca_ben, 4))
becca_sal <- c(rep(becca_mon, 4), rep(becca_stat, 3), rep(becca_ben, 4))
becca_sal <- c(rep(becca_mon, 4), rep(becca_stat, 3), rep(becca_ben, 4), becca_half)
becca_half <- 2558 / 2
becca_sal <- c(rep(becca_mon, 4), rep(becca_stat, 3), rep(becca_ben, 4), becca_half)
Budget <- data.frame(month.name, jerome_sal, becca_sal)
budget <- data.frame(month.name, jerome_sal, becca_sal)
view(budget)
View(budget)
rm("Budget")
summary(budget)
dim(budget)
rent <- rep(1300, 12)
house_bills <- rep(119, 12)
budget <- data.frame(budget, rent, bills)
budget <- data.frame(budget, rent, house_bills)
income <- c(jerome_sal, becca_sal)
income <- matrix(jerome_sal, becca_sal)
income <- data.frame(jerome_sal, becca_sal)
budget <- data.frame(budget, income)
View(budget)
library(dplyr)
mutate(budget, income = jerome_sal + becca_sal)
budget <- subset(budget, select = -c(jerome_sal.1, becca_sal.1))
budget
mutate(budget, income = jerome_sal + becca_sal)
mutate(budget, outgoing = rent + house_bills)
mutate(budget, income = jerome_sal + becca_sal)
mutate(budget, income = jerome_sal + becca_sal, outgoing = rent + house_bills)
mutate(budget, balance = income - outgoing)
budget2 <- mutate(budget, income = jerome_sal + becca_sal, outgoing = rent + house_bills)
mutate(budget2, balance = income - outgoing)
food <- rep(700, 12)
Rohan <- rep(200, 12)
travel <- rep(75, 12)
football <- rep(20,12)
yoga <- rep(40, 12)
going_out <- (200, 12)
going_out <- rep(200, 12)
class(budget2)
budget3 <- data.frame(budget2, food, Rohan, travel, football, yoga, going_out)
budget3
budget2 <- mutate(budget2, balance = income - outgoing)
budget3 <- data.frame(budget2, food, Rohan, travel, football, yoga, going_out)
budget3
budget4 <- mutate(budget3, outgoing = ougoing + food, Rohan, travel, football, yoga, going_out)
budget4 <- mutate(budget3, outgoing = outgoing + food, Rohan, travel, football, yoga, going_out)
budget4
budget4 <- mutate(budget3, outgoing = outgoing + food, Rohan, travel, football, yoga, going_out, balance = income - outgoing)
budget4
jerome_sal <- rep(2369, 12)
budget4
growth rate <- (y - x)/x
growth <- (55000 - 45000)/45000
sal15p <- 45000 * 1.15
sal30p <- 45000 * 1.3
sal10p <- 45000 * 1.10
jerome_sal10 <- rep(2578, 12)
budget_10% <- data.frame(budget4, jerome_sal10)
budget_10 <- data.frame(budget4, jerome_sal10)
budget_10 <- mutate(budget4, income = becca_sal + jerome_sal10, balance = income - outgoing)
budget_10
budget_50 <- mutate(budget4, income = becca_sal + jerome_sal10, balance = income - outgoing)
jerome_sal55 <- rep(2767, 12)
budget_55 <- mutate(budget4, income = becca_sal + jerome_sal55, balance = income - outgoing)
budget_55
house_bills <- rep(235, 12)
?help
load(Titanic)
View(Titanic)
Head(Titanic)
head(Titanic)
Titanic
save.image("budget2016.RData")
rm(list=ls())
install.packages("kernSmooth")
install.packages("KernSmooth")
library(KernSmooth)
setwd("/Users/jahye01/Documents/DataScience/Courses/DataScienceJH/Rprog")
getwd()
rp_hw1 <- read.csv("hw1_data.csv")
head(rp_hw1)
dim(rp_wh1)
str(rp_wh1)
dim(rp_hw1)
re_hw1[152:153]
rp_hw1[152:153]
rp_hw1[152:153,]
rp_hw1[47,re_hw1$Ozone]
rp_hw1[47,rp_hw1$Ozone]
rp_hw1[47,1]
rp_hw1$Ozone(is.na)
is.na(rp_hw1$Ozone)
str(rp_hw1)
summary(rp_hw1)
ozone_31 <- [rp_hw1$Ozone<31,]
ozone_31 <- rp_hw1$Ozone<31
summary(ozone_31)
q18 <- rp_hw1[rp_hw1$Ozone > 31, rp_hw1$Temp > 90]
q18 <- rp_hw1[rp_hw1$Ozone > 31 & rp_hw1$Temp > 90]
q18 <- rp_hw1[rp_hw1$Ozone > 31 & rp_hw1$Temp > 90,]
summary(q18)
q19 <- subset(rp_hw1, Month == 6)
mean(q19$temp)
mean(q19$Temp)
max(rp_hw1$Month == 5)
max(rp_hw1$Ozone, rp_hw1$Month == 5)
q20 <- subset(rp_hw1, Month == 5)
max(q20$Ozone)
max(q20$Ozone)
summary(q20$Ozone)
source('~/.active-rstudio-document')
install.packages("KernSmooth")
save.image("w1q.Rdata")
library(swirl)
library(swirl)
install.packages("swirl")
install.packages("swirl")
install.packages("Swirl")
install.packages("swirl")
install.packages("swirl")
require(swirl)
library(swirl)
